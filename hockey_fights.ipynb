{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd09164a3399a70d355c381b62813f30880ed90ca5a6f321bf0d85375640bda7ee5",
   "display_name": "Python 3.7.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "9164a3399a70d355c381b62813f30880ed90ca5a6f321bf0d85375640bda7ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAME = 10\n",
    "IMG_SIZE = 100\n",
    "\n",
    "LR = 0.0001\n",
    "VIOLENCE_DIR = './Hockey_fights/Violence/'\n",
    "NON_VIOLENCE_DIR = './Hockey_fights/Non-violence/'\n"
   ]
  },
  {
   "source": [
    "Extracting Dataframes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "def extract_frames(folder):\n",
    "    count = 0\n",
    "    for files in os.listdir(folder):\n",
    "        cap = cv2.VideoCapture(os.path.join(folder, files))\n",
    "        sucess, image = cap.read()\n",
    "        sucess = True\n",
    "        while sucess:\n",
    "            sucess, image = cap.read()\n",
    "            cv2.imwrite(\"./Hockey_fights/Dataframes/\"+ str(count) + \".jpg\", image)\n",
    "\n",
    "            if cv2.waitKey(10) == 27:\n",
    "                break\n",
    "            count += 1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0037d7910f4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./Hockey_fights/Dataframes/\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m27\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for files in os.listdir(VIOLENCE_DIR):\n",
    "    cap = cv2.VideoCapture(os.path.join(VIOLENCE_DIR, files))\n",
    "    sucess, image = cap.read()\n",
    "    #print(sucess)\n",
    "    sucess = True\n",
    "    while sucess:\n",
    "        sucess, image = cap.read()\n",
    "        if not sucess:\n",
    "            break \n",
    "        cv2.imwrite(\"./Hockey_fights/Dataframes/\"+ str(count) + \".jpg\", image)\n",
    "\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            break\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20057\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'NON_VIOLENCE_DIR' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3a0c257d4d1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNON_VIOLENCE_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNON_VIOLENCE_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msucess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#print(sucess)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msucess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NON_VIOLENCE_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "for files in os.listdir(NON_VIOLENCE_DIR):\n",
    "    cap = cv2.VideoCapture(os.path.join(NON_VIOLENCE_DIR, files))\n",
    "    sucess, image = cap.read()\n",
    "    #print(sucess)\n",
    "    sucess = True\n",
    "    while sucess:\n",
    "        sucess, image = cap.read()\n",
    "        if not sucess:\n",
    "            break \n",
    "        cv2.imwrite(\"./Hockey_fights/Dataframes/\"+ str(count) + \".jpg\", image)\n",
    "\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            break\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "40056\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataset = []\n",
    "    image = []\n",
    "    limit = 0\n",
    "    c = 0\n",
    "\n",
    "    for file in tqdm(os.listdir('./Hockey_fights/Dataframes/')):\n",
    "        path = os.path.join('./Hockey_fights/Dataframes/', file)\n",
    "        img = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE))\n",
    "        image.append(np.array(img))\n",
    "        limit += 1\n",
    "        c += 1\n",
    "        if c == NUM_FRAME:\n",
    "            c = 0\n",
    "            if limit < 20057:\n",
    "                dataset.append([image, np.array([1, 0])])\n",
    "            elif limit >= 20056:\n",
    "                dataset.append([image, np.array([0, 1])])\n",
    "            image = []\n",
    "    \n",
    "    shuffle(dataset)\n",
    "    np.save('dataset.npy', dataset)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 40056/40056 [00:47<00:00, 843.81it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "data = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:-400]\n",
    "test = data[-400:]"
   ]
  },
  {
   "source": [
    "Creating the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(98, 98, 64)\n",
      "(10, 49, 49, 64)\n",
      "(10, 47, 47, 64)\n",
      "(10, 23, 23, 64)\n",
      "(10, 10, 10, 64)\n",
      "(10, 6400)\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 10, 100, 100, 3)] 0         \n",
      "_________________________________________________________________\n",
      "conv2d_177 (Conv2D)          (None, 10, 100, 100, 64)  1792      \n",
      "_________________________________________________________________\n",
      "conv2d_178 (Conv2D)          (None, 10, 98, 98, 64)    36928     \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem_241 (10, 98, 98, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_177 (MaxPoolin (10, 49, 49, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_179 (Conv2D)          (10, 47, 47, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_178 (MaxPoolin (10, 23, 23, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_180 (Conv2D)          (10, 21, 21, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_179 (MaxPoolin (10, 10, 10, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_51 (Flatten)         (10, 6400)                0         \n",
      "_________________________________________________________________\n",
      "tf.reshape_12 (TFOpLambda)   (1, 10, 6400)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_20 (Bidirectio (1, 64)                   1646848   \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (1, 64)                   4160      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (1, 32)                   2080      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (1, 1)                    33        \n",
      "=================================================================\n",
      "Total params: 1,765,697\n",
      "Trainable params: 1,765,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed,Dropout, Activation, Flatten,Conv2D, MaxPooling2D,LSTM,Bidirectional, Reshape\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "inputs = Input(shape=[10, IMG_SIZE, IMG_SIZE, 3], name= \"input\")\n",
    "convrnn = Conv2D(64, (3, 3), activation='relu', padding = 'same')(inputs)\n",
    "convrnn = Conv2D(64, (3, 3), activation='relu')(convrnn)\n",
    "print(convrnn[0][0].shape)\n",
    "convrnn = MaxPooling2D((2,2))(convrnn[0])\n",
    "print(convrnn.shape)\n",
    "convrnn = Conv2D(64, (3, 3), activation='relu')(convrnn)\n",
    "print(convrnn.shape)\n",
    "convrnn = MaxPooling2D((2,2))(convrnn)\n",
    "print(convrnn.shape)\n",
    "convrnn = Conv2D(64, (3, 3), activation='relu')(convrnn)\n",
    "convrnn = MaxPooling2D((2,2))(convrnn)\n",
    "print(convrnn.shape)\n",
    "convrnn = Flatten()(convrnn)\n",
    "print(convrnn.shape)\n",
    "\n",
    "convrnn = tf.reshape(convrnn, (1, 10, 6400))\n",
    "# print(convrnn.shape)\n",
    "\n",
    "lstm_fw = LSTM(units=32)\n",
    "lstm_bw = LSTM(units=32, go_backwards=True)\n",
    "bi_lstm = Bidirectional(lstm_fw, backward_layer=lstm_bw)(convrnn)\n",
    "\n",
    "convrnn = Dense(64, activation= 'relu')(bi_lstm)\n",
    "convrnn = Dense(32, activation= 'relu')(convrnn)\n",
    "output = Dense(1, activation='sigmoid')(convrnn)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "len(train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_4 (Conv2D)            (None, 10, 100, 100, 64)  1792      \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 10, 98, 98, 64)    36928     \n_________________________________________________________________\nmax_pooling3d_3 (MaxPooling3 (None, 10, 49, 49, 64)    0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 10, 47, 47, 64)    36928     \n_________________________________________________________________\nmax_pooling3d_4 (MaxPooling3 (None, 10, 23, 23, 64)    0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 10, 21, 21, 64)    36928     \n_________________________________________________________________\nmax_pooling3d_5 (MaxPooling3 (None, 10, 10, 10, 64)    0         \n_________________________________________________________________\nreshape_1 (Reshape)          (None, 10, 6400)          0         \n_________________________________________________________________\nbidirectional_3 (Bidirection (None, 64)                1646848   \n_________________________________________________________________\ndense_9 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_10 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndense_11 (Dense)             (None, 2)                 66        \n=================================================================\nTotal params: 1,765,730\nTrainable params: 1,765,730\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, Bidirectional, Conv2D, Dense, Flatten, MaxPooling2D, TimeDistributed, Reshape, MaxPooling3D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu', input_shape=(10, IMG_SIZE, IMG_SIZE, 3), padding=\"same\"))\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling3D((1, 2,2)))\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling3D((1, 2,2)))\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling3D((1, 2,2)))\n",
    "#cnn.add(Flatten())\n",
    "cnn.add(Reshape((10, 6400)))\n",
    "\n",
    "#cnn.summary()\n",
    "\n",
    "lstm_fw = LSTM(units=32)\n",
    "lstm_bw = LSTM(units=32, go_backwards = True)\n",
    "model = Sequential()\n",
    "#model.add(TimeDistributed(cnn, input_shape=(1, 10, 10, 64)))\n",
    "model.add(Bidirectional(lstm_fw, backward_layer = lstm_bw))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn.add(Bidirectional(lstm_fw, backward_layer = lstm_bw))\n",
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dense(32, activation='relu'))\n",
    "cnn.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "cnn.summary()\n",
    "opt = keras.optimizers.Adam(learning_rate=LR)\n",
    "cnn.compile(loss='categorical_crossentropy',optimizer='SGD',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('dataset.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size= 0.9, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1, 10, IMG_SIZE, IMG_SIZE, 3)\n",
    "Y = np.array([i[1] for i in train])\n",
    "\n",
    "x_valid = np.array([i[0] for i in test]).reshape(-1, 10, IMG_SIZE, IMG_SIZE, 3)\n",
    "y_valid = np.array([i[1] for i in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = X.astype('float32')/255\n",
    "x_valid = x_valid.astype('float32')/255\n",
    "#Y = Y.astype('float32').reshape((-1, 1))\n",
    "#y_valid = y_valid.astype('float32').reshape((-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3604, 2)\n(401, 2)\n(3604, 10, 100, 100, 3)\n(401, 10, 100, 100, 3)\n[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(y_valid.shape)\n",
    "print(X.shape)\n",
    "print(x_valid.shape)\n",
    "\n",
    "print(y_valid[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20 20\n"
     ]
    }
   ],
   "source": [
    "x_try = X[:20]\n",
    "y_try = Y[:20]\n",
    "print(len(x_try), len(y_try))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "226/226 [==============================] - 76s 337ms/step - loss: 0.0823 - accuracy: 0.9673 - val_loss: 0.3053 - val_accuracy: 0.8953\n",
      "Epoch 2/10\n",
      "226/226 [==============================] - 76s 337ms/step - loss: 0.1207 - accuracy: 0.9600 - val_loss: 0.1414 - val_accuracy: 0.9401\n",
      "Epoch 3/10\n",
      "226/226 [==============================] - 77s 339ms/step - loss: 0.0800 - accuracy: 0.9714 - val_loss: 0.1408 - val_accuracy: 0.9451\n",
      "Epoch 4/10\n",
      "226/226 [==============================] - 76s 338ms/step - loss: 0.0415 - accuracy: 0.9881 - val_loss: 0.1304 - val_accuracy: 0.9501\n",
      "Epoch 5/10\n",
      "226/226 [==============================] - 76s 338ms/step - loss: 0.0378 - accuracy: 0.9881 - val_loss: 0.1232 - val_accuracy: 0.9476\n",
      "Epoch 6/10\n",
      "226/226 [==============================] - 77s 339ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.1045 - val_accuracy: 0.9501\n",
      "Epoch 7/10\n",
      "226/226 [==============================] - 76s 338ms/step - loss: 0.0341 - accuracy: 0.9895 - val_loss: 1.7414 - val_accuracy: 0.6708\n",
      "Epoch 8/10\n",
      "226/226 [==============================] - 76s 338ms/step - loss: 0.0626 - accuracy: 0.9861 - val_loss: 0.1382 - val_accuracy: 0.9526\n",
      "Epoch 9/10\n",
      "226/226 [==============================] - 77s 339ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.1171 - val_accuracy: 0.9551\n",
      "Epoch 10/10\n",
      "226/226 [==============================] - 76s 338ms/step - loss: 0.0389 - accuracy: 0.9886 - val_loss: 0.1266 - val_accuracy: 0.9426\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20620008ac8>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "cnn.fit(X,Y,epochs=10,validation_data=(x_valid,y_valid),batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('CNN-BiLSTM.h5', overwrite=True, include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}