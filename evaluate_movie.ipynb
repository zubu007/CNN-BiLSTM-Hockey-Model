{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd09164a3399a70d355c381b62813f30880ed90ca5a6f321bf0d85375640bda7ee5",
   "display_name": "Python 3.7.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "9164a3399a70d355c381b62813f30880ed90ca5a6f321bf0d85375640bda7ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "from keras.models import load_model\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 100\n",
    "NUM_FRAME= 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_4 (Conv2D)            (None, 10, 100, 100, 64)  1792      \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 10, 98, 98, 64)    36928     \n_________________________________________________________________\nmax_pooling3d_3 (MaxPooling3 (None, 10, 49, 49, 64)    0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 10, 47, 47, 64)    36928     \n_________________________________________________________________\nmax_pooling3d_4 (MaxPooling3 (None, 10, 23, 23, 64)    0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 10, 21, 21, 64)    36928     \n_________________________________________________________________\nmax_pooling3d_5 (MaxPooling3 (None, 10, 10, 10, 64)    0         \n_________________________________________________________________\nreshape_1 (Reshape)          (None, 10, 6400)          0         \n_________________________________________________________________\nbidirectional_3 (Bidirection (None, 64)                1646848   \n_________________________________________________________________\ndense_9 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_10 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndense_11 (Dense)             (None, 2)                 66        \n=================================================================\nTotal params: 1,765,730\nTrainable params: 1,765,730\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = load_model('CNN-BiLSTM.h5')\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataset = []\n",
    "    image = []\n",
    "    limit = 0\n",
    "    c = 0\n",
    "\n",
    "    for file in tqdm(os.listdir('./Peliculas/Dataframes/')):\n",
    "        path = os.path.join('./Peliculas/Dataframes/', file)\n",
    "        img = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE))\n",
    "        image.append(np.array(img))\n",
    "        limit += 1\n",
    "        c += 1\n",
    "        if c == NUM_FRAME:\n",
    "            c = 0\n",
    "            if limit < 4792:\n",
    "                dataset.append([image, np.array([1, 0])])\n",
    "            elif limit >= 4792:\n",
    "                dataset.append([image, np.array([0, 1])])\n",
    "            image = []\n",
    "    \n",
    "    shuffle(dataset)\n",
    "    np.save('dataset_movie.npy', dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 9841/9841 [00:39<00:00, 249.61it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "data = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('dataset_movie.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size= 0.9, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "train[5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in data]).reshape(-1, 10, IMG_SIZE, IMG_SIZE, 3)\n",
    "Y = np.array([i[1] for i in data])\n",
    "\n",
    "#x_valid = np.array([i[0] for i in test]).reshape(-1, 10, IMG_SIZE, IMG_SIZE, 3)\n",
    "#y_valid = np.array([i[1] for i in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')/255\n",
    "#x_valid = x_valid.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(885, 2)\n(99, 2)\n(885, 10, 100, 100, 3)\n(99, 10, 100, 100, 3)\n[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(y_valid.shape)\n",
    "print(X.shape)\n",
    "print(x_valid.shape)\n",
    "\n",
    "print(y_valid[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "197/197 [==============================] - 10s 42ms/step - loss: 1.9003 - accuracy: 0.4573\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.9002829790115356, 0.4573170840740204]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "cnn.evaluate(x = X, y =Y, batch_size= 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}